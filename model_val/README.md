Due to GitHub's file size limitations, we have uploaded the fine-tuned tokenizer and clean model to Google Drive (https://drive.google.com/drive/folders/1x-MAophKqdvC7P8zu-COq1KUNS7j5Te6?dmr=1&ec=wgc-drive-globalnav-goto). 
When running the code, you need to download the model and weight files to your local computer in advance and replace the address path in the code.
